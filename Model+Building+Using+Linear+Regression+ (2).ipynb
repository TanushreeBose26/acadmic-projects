{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=7> <font color = darkblue> Model Building using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:30:51.427887Z",
     "start_time": "2020-08-20T08:30:49.003777Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd    \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=14\n",
    "plt.rcParams['axes.grid']=True\n",
    "plt.rcParams['figure.figsize'] = (5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this problem, we are predicting the Sales of Carseats for a store based on various other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:30:51.724372Z",
     "start_time": "2020-08-20T08:30:51.480534Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Carseats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAURAB~1\\AppData\\Local\\Temp/ipykernel_7796/2238724308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Carseats.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Carseats.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Carseats.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Description}$\n",
    "A simulated data set containing sales of child car seats at 400 different stores.\n",
    "\n",
    "$\\underline{Format}$\n",
    "A data frame with 400 observations on the following 11 variables.\n",
    "\n",
    "$\\underline{Sales}$\n",
    "Unit sales (in thousands) at each location\n",
    "\n",
    "$\\underline{CompPrice}$\n",
    "Price charged by competitor at each location\n",
    "\n",
    "$\\underline{Income}$\n",
    "Community income level (in thousands of dollars)\n",
    "\n",
    "$\\underline{Advertising}$\n",
    "Local advertising budget for company at each location (in thousands of dollars)\n",
    "\n",
    "$\\underline{Population}$\n",
    "Population size in region (in thousands)\n",
    "\n",
    "$\\underline{Price}$\n",
    "Price company charges for car seats at each site\n",
    "\n",
    "$\\underline{ShelveLoc}$\n",
    "A factor with levels Bad, Good and Medium indicating the quality of the shelving location for the car seats at each site\n",
    "\n",
    "$\\underline{Age}$\n",
    "Average age of the local population\n",
    "\n",
    "$\\underline{Education}$\n",
    "Education level at each location\n",
    "\n",
    "$\\underline{Urban}$\n",
    "A factor with levels No and Yes to indicate whether the store is in an urban or rural location\n",
    "\n",
    "$\\underline{US}$\n",
    "A factor with levels No and Yes to indicate whether the store is in the US or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us check the basic measures of Descriptive Statistics of the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:30:55.191799Z",
     "start_time": "2020-08-20T08:30:54.936829Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the data types of each of the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:30:56.704151Z",
     "start_time": "2020-08-20T08:30:56.675108Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at the distribution plot of the Y_train variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:30:58.508967Z",
     "start_time": "2020-08-20T08:30:58.181812Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(df['Sales'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's identify the feature with the strongest linear relation with Sales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corrwith(df.Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the scatterplot between 'Sales' and 'Price' and try to plot a line as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:01.859479Z",
     "start_time": "2020-08-20T08:31:01.847063Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_S_corr = pearsonr(df['Price'], df['Sales'])[0]\n",
    "P_S_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:03.195026Z",
     "start_time": "2020-08-20T08:31:02.695614Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['Price'], df['Sales'], label = round(P_S_corr, 3))\n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that these two variables are negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us now go ahead and build the Simple Linear Regression model between the variables 'Price' and 'Sales'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:06.085912Z",
     "start_time": "2020-08-20T08:31:05.901719Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:06.776665Z",
     "start_time": "2020-08-20T08:31:06.764524Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_SLR ='Sales~Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.ols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:08.050656Z",
     "start_time": "2020-08-20T08:31:07.614384Z"
    }
   },
   "outputs": [],
   "source": [
    "model_SLR = SM.ols(formula=formula_SLR, data=df).fit() \n",
    "model_SLR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = []\n",
    "model_perf = []\n",
    "\n",
    "model_name.append('SLR')\n",
    "model_perf.append(model_SLR.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice that the ${R^2}$ value in this case is very low. \n",
    "- Only around 20% variability in the dependent variable is being explained by the 'Price' variable in the.\n",
    "- For Simple Linear Regression, the square of the Pearson's correlation is same as the value of the ${R^2}$.\n",
    "Let us check it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:10.505778Z",
     "start_time": "2020-08-20T08:31:10.474020Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.square(P_S_corr))\n",
    "print(model_SLR.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before, we build the Multiple Linear Regression model, let us play around with the data and try different kinds of variable transformation to see whether they improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:13.854254Z",
     "start_time": "2020-08-20T08:31:13.839448Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_price = (df['Price']-np.mean(df['Price']))/np.std(df['Price'], ddof=1)\n",
    "scaled_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:14.498286Z",
     "start_time": "2020-08-20T08:31:14.480711Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_sales = (df['Sales']-np.mean(df['Sales']))/np.std(df['Sales'],ddof=1)\n",
    "scaled_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the distribution plot of the log of the 'Sales' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:16.386459Z",
     "start_time": "2020-08-20T08:31:15.899571Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(scaled_sales, kde = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(scaled_price, kde = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:16.539718Z",
     "start_time": "2020-08-20T08:31:16.486327Z"
    }
   },
   "outputs": [],
   "source": [
    "model_SLR_exp = SM.ols(formula='scaled_sales~scaled_price',data=df).fit()\n",
    "model_SLR_exp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We see that the **${R^2}$ value has remained the same after this transformation.** We can say that scaling a variable for Linear Regression will give us the same values as compared to the unscaled variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now build the Multiple Linear Regression model. But this data has Categorical data as well\n",
    "- So let us convert the categorical variables into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:18.615062Z",
     "start_time": "2020-08-20T08:31:18.599087Z"
    }
   },
   "outputs": [],
   "source": [
    "df_allvar = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:19.131479Z",
     "start_time": "2020-08-20T08:31:19.106580Z"
    }
   },
   "outputs": [],
   "source": [
    "df_allvar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us now check the correlation amongst the predictor variables just to make sure that the predictor variables are not highly correlated amongst themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:21.361700Z",
     "start_time": "2020-08-20T08:31:20.282703Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df_allvar.corr(), annot=True, mask=np.triu(df_allvar.corr(),1), cmap = 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now go ahead and build a linear regression on the data with all the levels of categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Model using dummy without dropping one level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:22.141277Z",
     "start_time": "2020-08-20T08:31:22.132960Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_1 = 'Sales~CompPrice+Income+Advertising+Population+Price+Age+Education+ShelveLoc_Bad+ShelveLoc_Good+ShelveLoc_Medium+Urban_No+Urban_Yes+US_No+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:22.835206Z",
     "start_time": "2020-08-20T08:31:22.602005Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_1 = SM.ols(formula=formula_MLR_1,data=df_allvar).fit()\n",
    "model_MLR_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('All data')\n",
    "model_perf.append(model_MLR_1.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The p-value for the variable 'Population' and the variable 'Education' is high. These variables are statistically not important. But we need to understand these variables from a business point of view and then only drop the variables if required.\n",
    "\n",
    "- But here in the above model built, we have not dropped at least one of the categories while creating the dummy variables and thus there seems to be a problem of multicollinearity in the data. \n",
    "\n",
    "- We will see the test of multicollinearity in a short while but we will rebuild the model.\n",
    "\n",
    "- For rebuilding the model, we will re-create the data set with appropriate levels of dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Model using appropriate number of dummy variable levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:24.719290Z",
     "start_time": "2020-08-20T08:31:24.698520Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:25.323567Z",
     "start_time": "2020-08-20T08:31:25.297125Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = darkgreen> Discussion: Should we always one hot encode our categorical varaibles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we see that the number of columns have been reduced and only the necessary columns are present.\n",
    "- Let us now check the correlation matrix in the form of a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:28.327717Z",
     "start_time": "2020-08-20T08:31:27.112023Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df_dummy.corr(),annot=True,mask=np.triu(df_dummy.corr(),+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:33.625232Z",
     "start_time": "2020-08-20T08:31:33.615043Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_2 ='Sales~CompPrice+Income+Advertising+Population+Price+Age+Education+ShelveLoc_Good+ShelveLoc_Medium+Urban_Yes+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:34.350079Z",
     "start_time": "2020-08-20T08:31:34.236241Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_2 = SM.ols(formula=formula_MLR_2,data=df_dummy).fit()\n",
    "model_MLR_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop first dummy')\n",
    "model_perf.append(model_MLR_2.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color = darkblue> Now, let us check and treat the multicollinearity problem if it is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Variance Inflation Factor (VIF) regresses the dependent variables amongst themselves and then calculates the VIF values based on the ${R^2}$ of each such regression.\n",
    "\n",
    "- ### The formula for VIF calculation is :\n",
    "- # \\begin{equation*} VIF  =  \\frac{1}{1 - {R^2}} \\end{equation*} \n",
    "- ### VIF threshold value of 5 is commonly used to leave out columns. Sometimes 2 or 10 are also considered as VIF threshold values\n",
    "- ### A VIF value of 5 means that we can choose to drop a predictor variable whose 80% variation is being explained by the other predictor variables.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the Variance Inflation Factor by an user defined function.\n",
    "Below is the function that is created to calculate the Variance Inflation Factor (VIF) values.\n",
    "- 1st line code is about defining a function \"vif_cal\" which we shall use to call the function.\n",
    "- We then define the x or the predictor variables. \n",
    "- The second step is to get the data in each of the column variable\n",
    "- Then we define a 'for' loop where the y or the target variable is defined as one of the variables of the input data set.\n",
    "- The x or the predictor variables are then defined as all the variables of the input data except the y or the target variable defined in the last step.\n",
    "- We then fit a regression function and calculate the ${R^2}$ value which is being stored in the variable rsq.\n",
    "- Another variable by the name of vif is defined and the ${R^2}$ value is put into the formula of the vif calculation.\n",
    "- Lastly, we print this value.\n",
    "\n",
    "This process is being repeated for all the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:36.664381Z",
     "start_time": "2020-08-20T08:31:36.650827Z"
    }
   },
   "outputs": [],
   "source": [
    "def vif_cal(input_data):\n",
    "    '''\n",
    "    input_data: Dataframe of features\n",
    "    '''\n",
    "    x_vars = input_data\n",
    "    xvar_names = input_data.columns\n",
    "    for i in range(len(xvar_names)):\n",
    "        y = x_vars[xvar_names[i]] \n",
    "        x = x_vars[xvar_names.drop(xvar_names[i])]\n",
    "        rsq = SM.ols(formula=\"y~x\", data=x_vars).fit().rsquared  \n",
    "        vif = round(1/(1-rsq), 2)\n",
    "        print (xvar_names[i], \" VIF = \" , vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:37.966811Z",
     "start_time": "2020-08-20T08:31:37.553934Z"
    }
   },
   "outputs": [],
   "source": [
    "vif_cal(input_data= df_dummy.drop('Sales', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let us understand the mathematical significance of any one of these vif calculations.\n",
    "- We will manually do the calculation behind this custom function for the variable 'CompPrice'.\n",
    "- # \\begin{equation*} VIF  =  \\frac{1}{1 - {R^2}} \\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:39.007833Z",
     "start_time": "2020-08-20T08:31:38.941397Z"
    }
   },
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model_vif = SM.ols(formula='CompPrice~Income+Advertising+Population+Price+Age+Education+ShelveLoc_Good+ShelveLoc_Medium+Urban_Yes+US_Yes',\n",
    "                   data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vif.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:40.507336Z",
     "start_time": "2020-08-20T08:31:40.492950Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculating the vif from the above formula\n",
    "round(1/(1-model_vif.rsquared),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the vif value for all the predictor variables is calculated.\n",
    "\n",
    "- We know that the value of ${R^2}$ of any regression lies between 0 and 1. 0 means that all the predictor variables combined can only explain 0% in the variation in the target variable where as 1 means that all the predictor variables combined can explain 100% in the variation in the target variable.\n",
    "\n",
    "- Higher the value of ${R^2}$, 1 - ${R^2}$ will be correspondingly smaller. Thus, the inverse of a very small number will be a huge number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = darkblue> Lets do a few more VIF exercises to understand it better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us check the vif of the data frame which contains the dummy variables without dropping a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_cal(input_data= df_allvar.drop('Sales', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above values corroborates our understanding of vif. Since there was a presence of multicollinearity we see that the vif values are very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us check how the vif values would differ if we forcefully enter a variable which should be having a strong collinearity with one of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:48.948846Z",
     "start_time": "2020-08-20T08:31:48.941497Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy_copy = df_dummy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:49.594595Z",
     "start_time": "2020-08-20T08:31:49.565677Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy_copy['Incomesq'] = np.square(df_dummy_copy['Income'])\n",
    "#introducing a variable which is the square one of the predictor variables\n",
    "df_dummy_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:50.271120Z",
     "start_time": "2020-08-20T08:31:50.258409Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_cal(input_data= df_dummy_copy.drop('Sales', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the vif has indeed increased for the Income and Incomesq variable. We can go ahead and drop the 'Incomesq' variable as that variable has been derived from the 'Income' variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of the VIF exercises\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coming back to our last model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLR_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_cal(input_data= df_dummy.drop('Sales', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On our original model, we see that the vif of the 'Advertising' is comparatively a little higher but it is not so high as to drop it. We will keep it in our model. But can drop the 'US_Yes' variable as that has a comparatively high vif along with a high p-value indicating the particular variable might not be significant for this model.\n",
    "\n",
    "- If variables are decided to be dropped on the basis of vif, we will drop them one by one. After one variable is dropped we are going to run the regression model and the vif function. Then if needed we will drop more variables. \n",
    "\n",
    "- Dropping variables means losing out on information. That can hamper the predictive as well as the descriptive power of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color = darkblue> Dropping features based on high P Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We notice that the p-value for the t-statistic calculation for the 'Population' variable is the highest (higher than 0.05).\n",
    "- For the $\\underline{t-statistic}$ for every co-efficient of the Linear Regression the null and alternate Hypothesis is as follows:\n",
    "- #### ${H_0}$ : The variable is significant.\n",
    "- #### ${H_1}$:  The variable is not significant.\n",
    "- Lower the p-value for the t-statistic more significant are the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Model without the 'Population' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:31:59.342106Z",
     "start_time": "2020-08-20T08:31:59.332676Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_3 = 'Sales~CompPrice+Income+Advertising+Price+Age+Education+ShelveLoc_Good+ShelveLoc_Medium+Urban_Yes+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:00.020007Z",
     "start_time": "2020-08-20T08:31:59.921508Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_3 = SM.ols(formula=formula_MLR_3,data=df_dummy).fit()\n",
    "model_MLR_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('w/o population')\n",
    "model_perf.append(model_MLR_3.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is almost no change in the ${R^2}$ values. \n",
    "\n",
    "- While adding or subtracting variables from a regression model to refine the model, we need to be very careful about the Adjusted ${R^2}$ values. Adding any particular value which is not significant can increase the ${R^2}$ value but the Adjusted ${R^2}$ changes by the addition or the subtraction of significant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the $R^2$ and adjusted $R^2$ values for the $2^{nd}$ and $3^{rd}$ Multiple Linear Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:02.080537Z",
     "start_time": "2020-08-20T08:32:02.071002Z"
    }
   },
   "outputs": [],
   "source": [
    "print('For the second MLR model:','\\n')\n",
    "\n",
    "print('Rsquared',model_MLR_2.rsquared)\n",
    "print('Adjusted Rsquared',model_MLR_2.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:02.659268Z",
     "start_time": "2020-08-20T08:32:02.649193Z"
    }
   },
   "outputs": [],
   "source": [
    "print('For the third MLR model:','\\n')\n",
    "\n",
    "print('Rsquared',model_MLR_3.rsquared)\n",
    "print('Adjusted Rsquared',model_MLR_3.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the particular information about the population does not help us in predicting the 'Sales' as compared to the other information that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Drop 'CompPrice'\n",
    "- Let us see what happens when we drop a statistically significant variable from the model.\n",
    "- In this case,we will drop the 'CompPrice' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:07.141226Z",
     "start_time": "2020-08-20T08:32:07.132566Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_4 = 'Sales~Income+Advertising+Population+Price+Age+Education+ShelveLoc_Good+ShelveLoc_Medium+Urban_Yes+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:07.841925Z",
     "start_time": "2020-08-20T08:32:07.728849Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_4 = SM.ols(formula=formula_MLR_4,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:08.332068Z",
     "start_time": "2020-08-20T08:32:08.276341Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop Comp Price')\n",
    "model_perf.append(model_MLR_4.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per our understanding, we see that both the Adjusted ${R^2}$ and the ${R^2}$ values have dropped massively. The p-values of t-statistic of certain variables have also changed. This indicates that as per the last iteration of the model a few  values have become more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us again check the earlier model before dropping any statistically significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:17.289965Z",
     "start_time": "2020-08-20T08:32:17.236593Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 - Drop Urban Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now go ahead and drop the 'Urban_Yes' variable as that does not seem very statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:23.323996Z",
     "start_time": "2020-08-20T08:32:23.315922Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_5 = 'Sales~CompPrice+Income+Advertising+Price+Age+Education+ShelveLoc_Good+ShelveLoc_Medium+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:24.179183Z",
     "start_time": "2020-08-20T08:32:24.116198Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_5 = SM.ols(formula=formula_MLR_5,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:24.790692Z",
     "start_time": "2020-08-20T08:32:24.752242Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop Urban Yes')\n",
    "model_perf.append(model_MLR_5.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost no change in the ${R^2}$ and Adjusted ${R^2}$ is observed thus confirming the fact that the variable was indeed not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: Drop Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check the diagnostics of the model after dropping the 'Education' variable as that does not seem significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:32.200084Z",
     "start_time": "2020-08-20T08:32:32.190928Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_6 = 'Sales~CompPrice+Income+Advertising+Price+Age+ShelveLoc_Good+ShelveLoc_Medium+US_Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:33.181137Z",
     "start_time": "2020-08-20T08:32:33.126084Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_6 = SM.ols(formula=formula_MLR_6,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:33.839407Z",
     "start_time": "2020-08-20T08:32:33.799947Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop Education')\n",
    "model_perf.append(model_MLR_6.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above model we can thus conclude that Education is not a significant variable when it comes to predicting the sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7 - drop US Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the p-value of the P value of 'US_Yes', the variable does not seem significant. We will run the model by dropping the variable and then we will again check the values of $R^2$ and adjusted $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:39.849755Z",
     "start_time": "2020-08-20T08:32:39.842011Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_7 = 'Sales~CompPrice+Income+Advertising+Price+Age+ShelveLoc_Good+ShelveLoc_Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:40.597565Z",
     "start_time": "2020-08-20T08:32:40.544111Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_7 = SM.ols(formula=formula_MLR_7,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:41.237244Z",
     "start_time": "2020-08-20T08:32:41.199722Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop US Yes')\n",
    "model_perf.append(model_MLR_7.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the $R^2$ and adjusted $R^2$ values does not change much if we drop the 'US_Yes' variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8: Drop Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drop the 'Income' variable once and run the model. Here all the variables are significant but we are trying to see that within these significant variables if we drop the least significant one, do the output change a lot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:48.293457Z",
     "start_time": "2020-08-20T08:32:48.286392Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_8 = 'Sales~CompPrice+Advertising+Price+Age+ShelveLoc_Good+ShelveLoc_Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:49.096334Z",
     "start_time": "2020-08-20T08:32:49.044958Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_8 = SM.ols(formula=formula_MLR_8,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:49.757530Z",
     "start_time": "2020-08-20T08:32:49.723826Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop Income')\n",
    "model_perf.append(model_MLR_8.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the $R^2$ and the adjusted $R^2$ values with model 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:51.507386Z",
     "start_time": "2020-08-20T08:32:51.493298Z"
    }
   },
   "outputs": [],
   "source": [
    "print('For the seventh MLR model:','\\n')\n",
    "\n",
    "print('Rsquared',model_MLR_7.rsquared)\n",
    "print('Adjusted Rsquared',model_MLR_7.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:52.604549Z",
     "start_time": "2020-08-20T08:32:52.592920Z"
    }
   },
   "outputs": [],
   "source": [
    "print('For the eigth MLR model:','\\n')\n",
    "\n",
    "print('Rsquared',model_MLR_8.rsquared)\n",
    "print('Adjusted Rsquared',model_MLR_8.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:53.747300Z",
     "start_time": "2020-08-20T08:32:53.735573Z"
    }
   },
   "outputs": [],
   "source": [
    "print('We notice that there is drop of',round((model_MLR_7.rsquared - model_MLR_8.rsquared),7),'and',round((model_MLR_7.rsquared_adj-model_MLR_8.rsquared_adj),7),'for Rsquared and adjusted Rsquared respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the p-values once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:55.836876Z",
     "start_time": "2020-08-20T08:32:55.824283Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_8.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9: Drop ShelveLoc: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drop the 'ShelveLoc_Medium' variable. Again dropping one more least significant variable among the most significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:32:59.749993Z",
     "start_time": "2020-08-20T08:32:59.741588Z"
    }
   },
   "outputs": [],
   "source": [
    "formula_MLR_9 = 'Sales~CompPrice+Advertising+Price+Age+ShelveLoc_Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:00.425780Z",
     "start_time": "2020-08-20T08:33:00.383168Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_9 = SM.ols(formula=formula_MLR_9,data=df_dummy).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:01.095163Z",
     "start_time": "2020-08-20T08:33:01.056204Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.append('drop Shelve Medium')\n",
    "model_perf.append(model_MLR_9.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a huge drop in the values of $R^2$ and adjusted $R^2$ if we drop the 'Shelve_Medium'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:03.611371Z",
     "start_time": "2020-08-20T08:33:03.599719Z"
    }
   },
   "outputs": [],
   "source": [
    "print('We notice that there is drop of',round((model_MLR_8.rsquared - model_MLR_9.rsquared),6),'and',round((model_MLR_8.rsquared_adj-model_MLR_9.rsquared_adj),6),'for Rsquared and adjusted Rsquared respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus seen the effects and power of various variables on describing the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = darkblue> Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame({'model_name': model_name, 'model_perf': model_perf})\n",
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### We will use Model 7 and Model 8 to predict and check the model evaluation.\n",
    "- #### Model 7 because, it has a high Adjusted R Square, with least number of features\n",
    "- #### Model 8, for comparison sake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 & 8 - Prediction and Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:22.256870Z",
     "start_time": "2020-08-20T08:33:22.245832Z"
    }
   },
   "outputs": [],
   "source": [
    "model_MLR_7_pred = model_MLR_7.fittedvalues\n",
    "model_MLR_8_pred = model_MLR_8.fittedvalues\n",
    "model_MLR_7_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) =  plt.subplots(nrows=1, ncols=2, figsize=(15,5), sharey=True)\n",
    "\n",
    "ax1.scatter(df_dummy['Sales'], model_MLR_7_pred)\n",
    "ax1.set_title('Model 7 predictions')\n",
    "\n",
    "ax2.scatter(df_dummy['Sales'],model_MLR_8_pred)\n",
    "ax2.set_title('Model 8 predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the boxplot and the distplot of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:31.273479Z",
     "start_time": "2020-08-20T08:33:30.472173Z"
    }
   },
   "outputs": [],
   "source": [
    "f,a =  plt.subplots(1,2, sharex=True, sharey=False, squeeze=False, figsize=(15,5))\n",
    "\n",
    "#Plotting the distplot and the boxplot of the residuals for model 8\n",
    "\n",
    "plot_0 = sns.histplot(model_MLR_7.resid, ax=a[0][0], kde=True)\n",
    "a[0][0].set_title('Model 7: Distplot of the residuals')\n",
    "\n",
    "plot_1 = sns.histplot(model_MLR_8.resid, ax=a[0][1], kde=True)\n",
    "a[0][1].set_title('Model 8: Distplot of the residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a =  plt.subplots(1,2, sharex=True, sharey=False, squeeze=False, figsize=(15,5))\n",
    "\n",
    "#Plotting the distplot and the boxplot of the residuals for model 8\n",
    "\n",
    "plot_0 = sns.boxplot(x= model_MLR_7.resid, ax=a[0][0])\n",
    "a[0][0].set_title('Model 7: Boxplot of the residuals')\n",
    "\n",
    "plot_1 = sns.boxplot(x = model_MLR_8.resid, ax=a[0][1])\n",
    "a[0][1].set_title('Model 8: Boxplot of the residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:31.914397Z",
     "start_time": "2020-08-20T08:33:31.826560Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:34.551347Z",
     "start_time": "2020-08-20T08:33:34.540273Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(df_dummy['Sales'], model_MLR_7_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8 - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:36.284059Z",
     "start_time": "2020-08-20T08:33:36.275062Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(df_dummy['Sales'], model_MLR_8_pred,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = darkblue>Only for Predictive purposes of Linear Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we only wanted to predict using Linear Regression and were not looking for the model building aspect of it, we can do that as well. \n",
    "- For this exercise, we will use the same variables as of Model 2, Model 7, Model 8 and Model 9.\n",
    "###  Key Differences in Predictive Modelling\n",
    "- #### We will split the data into train and test and get an idea about the expected quality of predictions in future.\n",
    "- #### We will need to choose a metric of interest. Lets choose RMSE.\n",
    "- #### build the model on the training data and check the RMSE on the test data.\n",
    "\n",
    "###### Note: We are going to build all the models, get their predictions and then go on to evaluate those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:40.441688Z",
     "start_time": "2020-08-20T08:33:40.359311Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:41.025605Z",
     "start_time": "2020-08-20T08:33:41.017432Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:41.659866Z",
     "start_time": "2020-08-20T08:33:41.636407Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into the dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:43.093149Z",
     "start_time": "2020-08-20T08:33:43.080659Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_dummy.drop('Sales', axis=1)\n",
    "Y = df_dummy['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train (70%) and test (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:44.541400Z",
     "start_time": "2020-08-20T08:33:44.533187Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:45.205198Z",
     "start_time": "2020-08-20T08:33:45.192046Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only Model 2 variables to build the model on the training data and predict on the training as well as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:47.288268Z",
     "start_time": "2020-08-20T08:33:47.209942Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = lr.fit(X_train[['CompPrice', 'Income', 'Advertising', 'Population', 'Price',\n",
    "       'Age', 'Education', 'ShelveLoc_Good', 'ShelveLoc_Medium', 'Urban_Yes', 'US_Yes']], Y_train)\n",
    "#We are only using Linear Regression as a predictive tool and not a descriptive tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:48.131723Z",
     "start_time": "2020-08-20T08:33:48.118708Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training Data Prediction\n",
    "model_2_pred_train = model_2.predict(X_train[['CompPrice', 'Income', 'Advertising', 'Population', 'Price',\n",
    "       'Age', 'Education', 'ShelveLoc_Good', 'ShelveLoc_Medium', 'Urban_Yes', 'US_Yes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:48.809809Z",
     "start_time": "2020-08-20T08:33:48.795852Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test Data Prediction\n",
    "model_2_pred_test = model_2.predict(X_test[['CompPrice', 'Income', 'Advertising', 'Population', 'Price',\n",
    "       'Age', 'Education', 'ShelveLoc_Good', 'ShelveLoc_Medium', 'Urban_Yes', 'US_Yes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only Model 7 variables to build the model on the training data and predict on the training as well as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:50.566786Z",
     "start_time": "2020-08-20T08:33:50.555338Z"
    }
   },
   "outputs": [],
   "source": [
    "model_7 = lr.fit(X_train[['CompPrice', 'Income', 'Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']],Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:51.343179Z",
     "start_time": "2020-08-20T08:33:51.331525Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training Data Prediction\n",
    "model_7_pred_train = model_7.predict(X_train[['CompPrice', 'Income', 'Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:52.261221Z",
     "start_time": "2020-08-20T08:33:52.242874Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test Data Prediction\n",
    "model_7_pred_test = model_7.predict(X_test[['CompPrice', 'Income', 'Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only Model 8 variables to build the model on the training data and predict on the training as well as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:54.117258Z",
     "start_time": "2020-08-20T08:33:54.102123Z"
    }
   },
   "outputs": [],
   "source": [
    "model_8 = lr.fit(X_train[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']],Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:55.025820Z",
     "start_time": "2020-08-20T08:33:55.008754Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training Data Prediction\n",
    "model_8_pred_train = model_8.predict(X_train[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:55.731730Z",
     "start_time": "2020-08-20T08:33:55.719240Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test Data Prediction\n",
    "model_8_pred_test = model_8.predict(X_test[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good', 'ShelveLoc_Medium']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only Model 9 variables to build the model on the training data and predict on the training as well as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:59.063658Z",
     "start_time": "2020-08-20T08:33:59.048016Z"
    }
   },
   "outputs": [],
   "source": [
    "model_9 = lr.fit(X_train[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good']],Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:59.916728Z",
     "start_time": "2020-08-20T08:33:59.902639Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training Data Prediction\n",
    "model_9_pred_train = model_9.predict(X_train[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:34:01.984289Z",
     "start_time": "2020-08-20T08:34:01.971460Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test Data Prediction\n",
    "model_9_pred_test = model_9.predict(X_test[['CompPrice','Advertising', 'Price',\n",
    "       'Age', 'ShelveLoc_Good']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE check for all the models built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:07.944542Z",
     "start_time": "2020-08-20T08:35:07.930354Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Data RMSE of model_2:',metrics.mean_squared_error(Y_train,model_2_pred_train,squared=False))\n",
    "print('Test Data RMSE of model_2:',metrics.mean_squared_error(Y_test,model_2_pred_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:25.686891Z",
     "start_time": "2020-08-20T08:35:25.677918Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Data RMSE of model_7:',metrics.mean_squared_error(Y_train,model_7_pred_train,squared=False))\n",
    "print('Test Data RMSE of model_7:',metrics.mean_squared_error(Y_test,model_7_pred_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:32.170692Z",
     "start_time": "2020-08-20T08:35:32.158161Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Data RMSE of model_8:',metrics.mean_squared_error(Y_train,model_8_pred_train,squared=False))\n",
    "print('Test Data RMSE of model_8:',metrics.mean_squared_error(Y_test,model_8_pred_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:38.077763Z",
     "start_time": "2020-08-20T08:35:38.063642Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Data RMSE of model_9:',metrics.mean_squared_error(Y_train,model_9_pred_train,squared=False))\n",
    "print('Test Data RMSE of model_9:',metrics.mean_squared_error(Y_test,model_9_pred_test,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best descriptive model might not be the best predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:43.605189Z",
     "start_time": "2020-08-20T08:35:41.792185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "f,a =  plt.subplots(2,2,sharex=True, figsize=(15,8))\n",
    "a[0][0].scatter(Y_train,model_2_pred_train)\n",
    "a[0][0].set_title('model_2')\n",
    "a[0][1].scatter(Y_train,model_7_pred_train)\n",
    "a[0][1].set_title('model_7')\n",
    "a[1][0].scatter(Y_train,model_8_pred_train)\n",
    "a[1][0].set_title('model_8')\n",
    "a[1][1].scatter(Y_train,model_9_pred_train)\n",
    "a[1][1].set_title('model_9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:35:45.405970Z",
     "start_time": "2020-08-20T08:35:43.783768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test Data\n",
    "f,a =  plt.subplots(2,2,sharex=True, figsize=(15,8))\n",
    "a[0][0].scatter(Y_test,model_2_pred_test)\n",
    "a[0][0].set_title('model_2')\n",
    "a[0][1].scatter(Y_test,model_7_pred_test)\n",
    "a[0][1].set_title('model_7')\n",
    "a[1][0].scatter(Y_test,model_8_pred_test)\n",
    "a[1][0].set_title('model_8')\n",
    "a[1][1].scatter(Y_test,model_9_pred_test)\n",
    "a[1][1].set_title('model_9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
